\author{Team: Circle}
%%%%%%%%%%%%%%%%%%%%%%%%
\title{GEO 365N/384S Seismic Data Processing \\ Final Project}

\begin{abstract}

In the final project, we process a 2D seismic line collected near the coast of Japan, over the Nankai trough. We go through processing steps from raw data to surface-consistent correction, CMP sorting, gain, spherical divergence correction, velocity analysis, NMO, DMO, stack, and migration.
  
\end{abstract}

\section{Data overview}
\inputdir{project}

\subsection{Geology}

\begin{enumerate}
\item The data were collected near the coast of Japan, over the Nankai trough, where the Philippines plate is subducting beneath Eurasia.
\end{enumerate}

\subsection{First look at data}

\begin{enumerate}
\item The data were collected by the University of Texas, the University of Tulsa, and the University of Tokyo. The original data is in SU, so we convert it to RSF files.
\item There are two data files: shot-ordered gathers (Figure~\ref{fig:shots}) and published stacked data (Figure~\ref{fig:stackd}). The data were collected in very deep water, approximate 6 seconds two-way travel time, which is 4.5 km if the water velocity is 1500 m/s. The shot-gather data has 326 shot gathers with 19057 traces. The total time length of a trace is 11 seconds with the sample interval of 0.002 seconds. The published stacked data has 2250 traces with total time length of 11 seconds and 0.004 seconds sample interval. The shot-gathers data has 401 CMPs while the stacked data is the output of 2869 CMPs. Therefore, the shot-gather file is a subset of stacked data.  
\item The number of traces per shot gather is Figure~\ref{fig:smask}. The first shot gather, 1687, has one trace, then the number of traces per gather increases to a maximum of 69 at gather 1735 and keeps constant through gather 1965. After gather 1965, the number of traces per gather decreases to 1 at the last gather, 2012. There are missing traces at some shot-gathers, for example at gather 1707 (Figure~\ref{fig:shot}). The average frequency spectra of shot gathers is Figure~\ref{fig:spectra}. Our data has low frequencies smaller than 10 Hz that need to be filtered. We later followed the example of the published dataset to resample the file from 2 ms to 4 ms sample interval to reduce our prestack processing load by half. The Nyquist frequency of 4 ms sample interval is 125 Hz. Typical seismic data has good high frequency content up to around 50-70 Hz, above this are usually noise. Therefore, we filtered high frequencies above 125 Hz to prevent aliasing and remove noise.    

\plot{stackd}{width=0.8\textwidth}{Published stacked data.}  
\plot{smask}{width=0.8\textwidth}{Number of traces per shot-gather.}  
\plot{shot}{width=0.8\textwidth}{Shot-gather 1707.}

\end{enumerate}

\section{Surface-consistent}

\begin{enumerate}

\item The first step is to do surface-consistent amplitude balancing. Typical seismic instruments introduce significant dirrect current (DC) offset that is effectively added to the desired signal from the sensor. We removed DC offset from the shot gathers data to facilitate processing and analysis of data (Figure~\ref{fig:shotsdc}). We then filtered the low frequency in the data (Figure~\ref{fig:shotsf}).

\item We created a mask to remove zero traces and calculated trace amplitudes of the shot gathers displayed in shot-offset coordinates (Figure~\ref{fig:varms}). The stripes in the amplitude might be caused by near-surface conditions in deploying sources and receivers. The horizontal stripes come from offset term (Figure~\ref{fig:off}). The vertical stripes come from shot term (Figure~\ref{fig:sht}). The diagonal stripes come from the CMP and receiver terms (Figure~\ref{fig:rcv} and Figure~\ref{fig:cmp}). After running iterative inversion, the stripes are predicted (Figure~\ref{fig:recvvscarms}. The shot gathers after the surface-consistent amplitude correction is the right figure in Figure~\ref{fig:shotsfc}.          

\multiplot{3}{shots,shotsdc,shotsf}{width=0.5\textwidth}{(a) Raw shot gathers (b) Shot gathers after DC removal. (c) Shot gathers after filtering low frequencies.}  
\multiplot{2}{spectra,spectraf}{width=0.8\textwidth}{(a) Raw data frequency spectra. (b) Frequency spectra after filtering low frequencies.}
\multiplot{4}{off,sht,rcv,cmp}{width=0.45\textwidth}{Estimated surface-consistent factors.} 
\multiplot{3}{varms,recvvscarms,recvadiff}{width=0.3\textwidth}{Trace amplitudes from the data. (a) Initial. (b) Estimated surface-consistent. (c) Difference.}
\plot{shotsfc}{width=0.8\textwidth}{(a) Raw shot gathers (b) Shot gathers after surface-consistent amplitude correction.}

\end{enumerate}

\section{CMP sorting}

\begin{enumerate}

\item The data was resampled to 4 ms sample interval and applied spherical divergence correction (Figure~\ref{fig:shots2}). We then sorted the data to CMP (Figure~\ref{fig:cmps}). The fold values of data is Figure~\ref{fig:cmask}. We have 401 CMPs but the first CMPs are not full fold. The first full-fold CMP gather is CMP 933 with 48 traces.

\plot{shots2}{width=0.8\textwidth}{Shot gathers after resampling.}
\plot{cmps}{width=0.8\textwidth}{CMP gathers.}
\plot{cmask}{width=0.8\textwidth}{Fold values of data.}    
 
\end{enumerate}

\section{Velocity analysis, NMO, and stack}

\begin{enumerate}

\item We examined CMP gather 1280 (Figure~\ref{fig:cmp1}). We did velocity analysis using semblance scan and automatically pick the velocity (Figure~\ref{fig:vscan}). We then applied NMO to flatten the events (Figure~\ref{fig:nmo1}).   

\plot{cmp1}{width=0.8\textwidth}{CMP 1280.}
\plot{vscan}{width=0.8\textwidth}{Velocity analysis for CMP 1280.}
\plot{nmo1}{width=0.8\textwidth}{CMP 1280 after NMO.}

\item We applied the same procedure with all CMP gathers. NMO velocity (Figure~\ref{fig:picks}) was picked using semblance scan. The events were flatten (Figure~\ref{fig:nmos}). We then stacked all the CMP gathers (Figure~\ref{fig:stack}). Our stack result does not resemble the published stacked data, which is actually a stacked and migrated file.

\plot{picks}{width=0.8\textwidth}{NMO velocity.}
\plot{nmos}{width=0.8\textwidth}{CMP gathers after NMO.}
\multiplot{2}{stack,stack-shot}{width=0.8\textwidth}{(a) Stacked data. (b) Published stacked data.}

\item We also tried DMO to correct for dips. We created a constant-velocity stack with 60 velocities starting from 1400 m/s and spacing interval of 20 m/s (Figure~\ref{fig:stacks}). We applied Fowler's method to transform the stack volume into the frequency-wavenumber domain and apply the velocity mapping (Figure~\ref{fig:map}). The result after applying Fowler's method is Figure~\ref{fig:dmo}. We then picked the DMO-corrected velocity automatically from the envelope (Figure~\ref{fig:vpick}). After the velocity was picked, we generated a DMO stack by slicing through the veolocity cube (Figure~\ref{fig:slice}). We examined CMP 380 to evaluate the velocity picking and to observe the change brought by DMO (Figure~\ref{fig:envelope}).      

\plot{stacks}{width=0.8\textwidth}{NMO stack with an ensemble of constant velocities.}
\sideplot{map}{width=\textwidth}{Fourier-domain velocity map used in Fowler's DMO method.}
\plot{dmo}{width=0.8\textwidth}{Nankai dataset after DMO stacking with an ensemble of constant velocities.}
\plot{vpick}{width=0.8\textwidth}{Migration velocity picked automatically from DMO stacks.}
\plot{slice}{width=0.8\textwidth}{DMO stack generated by slicing the constant-velocity stacks.}
\sideplot{envelope}{width=\textwidth}{Comparison of velocity analysis before and after DMO at a selected CMP location.}

\end{enumerate}

\section{Migration}



\bibliographystyle{seg}
\bibliography{SEG}


